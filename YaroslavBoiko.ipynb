{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 0. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.chdir(\"/Users/yaroslavboiko/Desktop/HW_Data_Analytics_1\")\n",
    "\n",
    "data = pd.read_stata('sipp1991.dta').values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1. Preparing the subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data=np.delete(data,[0,2,11],1)\n",
    "y_var=data[:,0]\n",
    "d_var=data[:,8]\n",
    "x_var=np.delete(data,[0,8],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2. Run regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22944349768021954"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "reg = LinearRegression().fit(x_var, y_var)\n",
    "reg.score(x_var, y_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3. Prediction with advanced algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_var, y_var, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators=20, random_state=0)\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 21762.665683308118\n",
      "Mean Squared Error: 3812939766.465818\n",
      "Root Mean Squared Error: 61749.00619820385\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4. Using Double ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "import math\n",
    "from scipy.optimize import minimize\n",
    "import sklearn\n",
    "from sklearn import tree\n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "from sklearn import neural_network\n",
    "from sklearn.model_selection import KFold\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class ML2Estimator:\n",
    "\n",
    "    def __init__(self, method=\"Tree\", method_binary=None, method_options=None, method_options_binary=None):\n",
    "        self.method=method\n",
    "        self.method_options=method_options\n",
    "        if method_binary is None:\n",
    "            if method==\"Lasso\":\n",
    "                self.method_binary=\"Lasso Logit\"\n",
    "            elif method==\"Ridge\":\n",
    "                self.method_binary=\"Ridge Logit\"\n",
    "            else:\n",
    "                self.method_binary=self.method\n",
    "        else:\n",
    "            self.method_binary=method_binary\n",
    "        self.method_options_binary=method_options_binary\n",
    "        if method_options_binary is None:\n",
    "            if self.method==self.method_binary:\n",
    "                self.method_options_binary=self.method_options\n",
    "        self.method_class=self._define_model(binary_outcome=False)\n",
    "        self.method_class_binary=self._define_model(binary_outcome=True)\n",
    "        self.pl_beta=None\n",
    "        self.pl_se=None\n",
    "        self.interactive_beta=None\n",
    "        self.interactive_se=None\n",
    "\n",
    "    def _define_lasso(self,binary_outcome):\n",
    "        if binary_outcome:\n",
    "            m_options=self.method_options_binary\n",
    "        else:\n",
    "            m_options=self.method_options\n",
    "        lasso_options={\"eps\":0.001, \"cv\":10,\"n_alphas\":100,\"alphas\":None,\"fit_intercept\":True, \"precompute\":'auto',\n",
    "            \"max_iter\":5000, \"tol\":0.0001, \"copy_X\":True, \"verbose\":False, \"n_jobs\":1, \"positive\":False, \"random_state\":None,\n",
    "            \"selection\":'cyclic'}\n",
    "        if m_options!=None:\n",
    "            if isinstance(m_options,dict):\n",
    "                for i in m_options:\n",
    "                    if i in lasso_options:\n",
    "                        lasso_options[i]=m_options[i]\n",
    "                    else:\n",
    "                        print(\"Error: \", i,\" is not a valid option entry\")\n",
    "                        print(\"valid option entries include:\")\n",
    "                        for i in lasso_options:\n",
    "                            print(i)\n",
    "                        raise NameError(\"Invalid option entry\")\t\t\n",
    "            else:\n",
    "                raise NameError(\"options must take the form of a dictionary\")\n",
    "        #print (lasso_options)\n",
    "        eps=lasso_options[\"eps\"]\n",
    "        cv=lasso_options[\"cv\"]\n",
    "        n_alphas=lasso_options[\"n_alphas\"]\n",
    "        alphas=lasso_options[\"alphas\"]\n",
    "        fit_intercept=lasso_options[\"fit_intercept\"]\n",
    "        precompute=lasso_options[\"precompute\"]\n",
    "        max_iter=lasso_options[\"max_iter\"]\n",
    "        tol=lasso_options[\"tol\"]\n",
    "        copy_X=lasso_options[\"copy_X\"]\n",
    "        verbose=lasso_options[\"verbose\"]\n",
    "        n_jobs=lasso_options[\"n_jobs\"]\n",
    "        positive=lasso_options[\"positive\"]\n",
    "        random_state=lasso_options[\"random_state\"]\n",
    "        selection=lasso_options[\"selection\"]\n",
    "        return linear_model.LassoCV(cv=cv, eps=eps, fit_intercept=fit_intercept, n_alphas=n_alphas, alphas=alphas,\n",
    "                precompute=precompute,max_iter=max_iter,tol=tol,copy_X=copy_X,verbose=verbose, n_jobs=n_jobs, positive=positive,\n",
    "                random_state=random_state,selection=selection)\n",
    "\n",
    "    def _define_lasso_logit(self,binary_outcome):\n",
    "        ll_options={\"cv\": 10, \"Cs\": 10, \"solver\":'SLSQP', \"solver_options\":None,\"low_val\": 1E-3, \"high_val\":1E3}\n",
    "        m_options=self.method_options_binary\n",
    "        if m_options!=None:\n",
    "            if isinstance(m_options,dict):\n",
    "                for i in m_options:\n",
    "                    if i in ll_options:\n",
    "                        ll_options[i]=m_options[i]\n",
    "                    else:\n",
    "                        print(\"Error: \",i,\" is not a valid option entry\")\n",
    "                        print(\"valid option entries include:\")\n",
    "                        for i in ll_options:\n",
    "                            print(i)\n",
    "                        raise NameError(\"Invalid option entry\")\t\n",
    "                        raise NameError(\"Invalid option entry\")\t\t\n",
    "            else:\n",
    "                raise NameError(\"options must take the form of a dictionary\")\n",
    "        #print (ll_options)\n",
    "        cv=ll_options[\"cv\"]\n",
    "        Cs=ll_options[\"Cs\"]\n",
    "        solver=ll_options[\"solver\"]\n",
    "        solver_options=ll_options[\"solver_options\"]\n",
    "        low_val=ll_options[\"low_val\"]\n",
    "        high_val=ll_options[\"high_val\"]\n",
    "        return LassoLogitCV(cv=cv, Cs=Cs, solver=solver, low_val=low_val, high_val=high_val)\n",
    "\n",
    "    def _define_random_forest(self,binary_outcome):\n",
    "        if binary_outcome:\n",
    "            m_options=self.method_options_binary\n",
    "        else:\n",
    "            m_options=self.method_options\n",
    "        rf_options={\"n_estimators\": 1000, \"criterion\": 'mse', \"max_depth\": None, \"min_samples_split\": 5, \"min_samples_leaf\": 5, \n",
    "            \"min_weight_fraction_leaf\":0.0, \"max_features\":\"auto\", \"max_leaf_nodes\":None, \"min_impurity_decrease\":1e-7, \n",
    "            \"bootstrap\":True, \"oob_score\":False, \"n_jobs\":1, \"random_state\":None, \"verbose\":0, \"warm_start\":False}\n",
    "        if m_options!=None:\n",
    "            if isinstance(m_options,dict):\n",
    "                for i in m_options:\n",
    "                    if i in rf_options:\n",
    "                        rf_options[i]=m_options[i]\n",
    "                    else:\n",
    "                        print(\"Error: \",i,\" is not a valid option entry\")\n",
    "                        print(\"valid option entries include:\")\n",
    "                        for i in rf_options:\n",
    "                            print(i)\n",
    "                        raise NameError(\"Invalid option entry\")\t\n",
    "                        raise NameError(\"Invalid option entry\")\t\t\n",
    "            else:\n",
    "                raise NameError(\"options must take the form of a dictionary\")\n",
    "        #print (rf_options)\n",
    "        n_estimators=rf_options[\"n_estimators\"]\n",
    "        criterion=rf_options[\"criterion\"]\n",
    "        max_depth=rf_options[\"max_depth\"]\n",
    "        min_samples_split=rf_options[\"min_samples_split\"]\n",
    "        min_samples_leaf=rf_options[\"min_samples_leaf\"]\n",
    "        min_weight_fraction_leaf=rf_options[\"min_weight_fraction_leaf\"]\n",
    "        max_features=rf_options[\"max_features\"]\n",
    "        max_leaf_nodes=rf_options[\"max_leaf_nodes\"]\n",
    "        min_impurity_decrease=rf_options[\"min_impurity_decrease\"]\n",
    "        bootstrap=rf_options[\"bootstrap\"]\n",
    "        oob_score=rf_options[\"oob_score\"]\n",
    "        n_jobs=rf_options[\"n_jobs\"]\n",
    "        random_state=rf_options[\"random_state\"]\n",
    "        verbose=rf_options[\"verbose\"]\n",
    "        warm_start=rf_options[\"warm_start\"]\n",
    "        return ensemble.RandomForestRegressor(n_estimators=n_estimators,criterion=criterion,max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "            max_features=max_features, max_leaf_nodes=max_leaf_nodes, min_impurity_decrease=min_impurity_decrease, bootstrap=bootstrap,\n",
    "            oob_score=oob_score,n_jobs=n_jobs, random_state=random_state, verbose=verbose)\n",
    "\n",
    "    def _define_regression_tree(self,binary_outcome):\n",
    "        if binary_outcome:\n",
    "            m_options=self.method_options_binary\n",
    "        else:\n",
    "            m_options=self.method_options\n",
    "        tree_options={\"criterion\":'mse', \"splitter\":'best', \"max_depth\":None, \"min_samples_split\":2, \"min_samples_leaf\":1,\n",
    "            \"min_weight_fraction_leaf\":0.0, \"max_features\":None, \"random_state\":None, \"max_leaf_nodes\":None, \n",
    "            \"min_impurity_decrease\":1e-07, \"presort\":False, \"n_jobs\": 1, \"cv\": 10, \"search_range_low\": 1, \"search_range_high\":11}\n",
    "        if m_options!=None:\n",
    "            if isinstance(m_options,dict):\n",
    "                for i in m_options:\n",
    "                    if i in tree_options:\n",
    "                        tree_options[i]=m_options[i]\n",
    "                    else:\n",
    "                        print(\"Error: \",i,\" is not a valid option entry\")\n",
    "                        print(\"valid option entries include:\")\n",
    "                        for i in tree_options:\n",
    "                            print(i)\n",
    "                        raise NameError(\"Invalid option entry\")\t\n",
    "                        raise NameError(\"Invalid option entry\")\t\t\n",
    "            else:\n",
    "                raise NameError(\"options must take the form of a dictionary\")\n",
    "        #print (tree_options)\n",
    "        criterion=tree_options[\"criterion\"]\n",
    "        splitter=tree_options[\"splitter\"]\n",
    "        min_samples_split=tree_options[\"min_samples_split\"]\n",
    "        min_weight_fraction_leaf=tree_options[\"min_weight_fraction_leaf\"]\n",
    "        max_features=tree_options[\"max_features\"]\n",
    "        random_state=tree_options[\"random_state\"]\n",
    "        max_leaf_nodes=tree_options[\"max_leaf_nodes\"]\n",
    "        min_impurity_decrease=tree_options[\"min_impurity_decrease\"]\n",
    "        presort=tree_options[\"presort\"]\n",
    "        n_jobs=tree_options[\"n_jobs\"]\n",
    "        cv=tree_options[\"cv\"]\n",
    "        search_range=range(tree_options[\"search_range_low\"],tree_options[\"search_range_high\"])\n",
    "        parameters = {'max_depth':search_range}\n",
    "        clf = sklearn.model_selection.GridSearchCV(tree.DecisionTreeRegressor(criterion=criterion, splitter=splitter,\n",
    "                min_samples_split=min_samples_split, min_weight_fraction_leaf=min_weight_fraction_leaf, max_features=max_features,\n",
    "                random_state=random_state,max_leaf_nodes=max_leaf_nodes, presort=presort),\n",
    "                parameters, n_jobs=n_jobs,cv=cv)\n",
    "        return clf\n",
    "    def _define_regression_tree_boosted(self,binary_outcome):\n",
    "        if binary_outcome:\n",
    "            m_options=self.method_options_binary\n",
    "        else:\n",
    "            m_options=self.method_options\n",
    "        ada_options={\"base_estimator\":None, \"n_estimators\":100, \"learning_rate\":0.001, \"loss\":'exponential', \"random_state\":None}\n",
    "        if m_options!=None:\n",
    "            if isinstance(m_options,dict):\n",
    "                for i in m_options:\n",
    "                    if i in ada_options:\n",
    "                        ada_options[i]=m_options[i]\n",
    "                    else:\n",
    "                        print(\"Error: \",i,\" is not a valid option entry\")\n",
    "                        print(\"valid option entries include:\")\n",
    "                        for i in ada_options:\n",
    "                            print(i)\n",
    "                        raise NameError(\"Invalid option entry\")\t\n",
    "                        raise NameError(\"Invalid option entry\")\t\t\n",
    "            else:\n",
    "                raise NameError(\"options must take the form of a dictionary\")\n",
    "        #print (ada_options)\n",
    "        base_estimator=ada_options[\"base_estimator\"]\n",
    "        n_estimators=ada_options[\"n_estimators\"]\n",
    "        learning_rate=ada_options[\"learning_rate\"]\n",
    "        loss=ada_options[\"loss\"]\n",
    "        random_state=ada_options[\"random_state\"]\n",
    "        return sklearn.ensemble.AdaBoostRegressor(base_estimator=base_estimator, n_estimators=n_estimators, learning_rate=learning_rate,\n",
    "            loss=loss, random_state=random_state)\n",
    "    def _define_ridge(self,binary_outcome):\n",
    "        if binary_outcome:\n",
    "            m_options=self.method_options_binary\n",
    "        else:\n",
    "            m_options=self.method_options\n",
    "        ridge_options={\"alphas\":40, \"fit_intercept\":True, \"scoring\":None,\n",
    "            \"cv\":10, \"gcv_mode\":None, \"store_cv_values\":False}\n",
    "        if m_options!=None:\n",
    "            if isinstance(m_options,dict):\n",
    "                for i in m_options:\n",
    "                    if i in ridge_options:\n",
    "                        ridge_options[i]=m_options[i]\n",
    "                    else:\n",
    "                        print(\"Error: \",i,\" is not a valid option entry\")\n",
    "                        print(\"valid option entries include:\")\n",
    "                        for i in ridge_options:\n",
    "                            print(i)\n",
    "                        raise NameError(\"Invalid option entry\")\t\n",
    "                        raise NameError(\"Invalid option entry\")\t\t\n",
    "            else:\n",
    "                raise NameError(\"options must take the form of a dictionary\")\n",
    "        #print (ridge_options)\n",
    "        alphas=ridge_options[\"alphas\"]\n",
    "        if (isinstance(alphas,int)):\n",
    "            alphas=np.exp(np.linspace(-3*math.log(10),3*math.log(10),alphas))\n",
    "        fit_intercept=ridge_options[\"fit_intercept\"]\n",
    "        scoring=ridge_options[\"scoring\"]\n",
    "        cv=ridge_options[\"cv\"]\n",
    "        gcv_mode=ridge_options[\"gcv_mode\"]\n",
    "        store_cv_values=ridge_options[\"store_cv_values\"]\n",
    "        return linear_model.RidgeCV(alphas=alphas, fit_intercept=fit_intercept,\n",
    "                scoring=scoring, cv=cv, gcv_mode=gcv_mode, store_cv_values=store_cv_values)\n",
    "\n",
    "    def _define_ridge_logit(self,binary_outcome):\n",
    "        rl_options={\"cv\": 10, \"Cs\": 10, \"solver\":'SLSQP', \"solver_options\":None,\"low_val\": 1E-3, \"high_val\":1E3}\n",
    "        m_options=self.method_options_binary\n",
    "        if m_options!=None:\n",
    "            if isinstance(m_options,dict):\n",
    "                for i in m_options:\n",
    "                    if i in rl_options:\n",
    "                        rl_options[i]=m_options[i]\n",
    "                    else:\n",
    "                        print(\"Error: \",i,\" is not a valid option entry\")\n",
    "                        print(\"valid option entries include:\")\n",
    "                        for i in rl_options:\n",
    "                            print(i)\n",
    "                        raise NameError(\"Invalid option entry\")\t\n",
    "                        raise NameError(\"Invalid option entry\")\t\t\n",
    "            else:\n",
    "                raise NameError(\"options must take the form of a dictionary\")\n",
    "        #print (rl_options)\n",
    "        cv=rl_options[\"cv\"]\n",
    "        Cs=rl_options[\"Cs\"]\n",
    "        solver=rl_options[\"solver\"]\n",
    "        solver_options=rl_options[\"solver_options\"]\n",
    "        low_val=rl_options[\"low_val\"]\n",
    "        high_val=rl_options[\"high_val\"]\n",
    "        return RidgeLogitCV(cv=cv, Cs=Cs, solver=solver, low_val=low_val, high_val=high_val)\n",
    "    def _define_model(self,binary_outcome=False):\n",
    "        if binary_outcome:\n",
    "            local_method=self.method_binary\n",
    "        else:\n",
    "            local_method=self.method\n",
    "        if local_method==\"Tree\":\n",
    "            return self._define_regression_tree(binary_outcome)\n",
    "        if local_method==\"Random Forest\":\n",
    "            return self._define_random_forest(binary_outcome)\n",
    "        if local_method==\"Boosted Tree\":\n",
    "            return self._define_regression_tree_boosted(binary_outcome)\n",
    "        if local_method==\"Ridge\":\n",
    "            return self._define_ridge(binary_outcome)\n",
    "        if local_method==\"Ridge Logit\":\n",
    "            if binary_outcome:\n",
    "                return self._define_ridge_logit(binary_outcome)\n",
    "            else:\n",
    "                raise NameError(\"The method 'Ridge Logit' can only be used to predict the binary outcome\" )\n",
    "        if local_method==\"Lasso\":\n",
    "            return self._define_lasso(binary_outcome)\n",
    "        if local_method==\"Lasso Logit\":\n",
    "            if binary_outcome:\n",
    "                return self._define_lasso_logit(binary_outcome)\n",
    "            else:\n",
    "                raise NameError(\"The method 'Lasso Logit' can only be used to predict the binary outcome\" )\n",
    "        else:\n",
    "            raise NameError(\"You have entered an unrecognized machine learning mehod.\\nRecognized methods include: `Lasso', `Ridge', `Tree' `Random Forest', and `Boosted Tree'\")\t\n",
    "\n",
    "    def fit(self,X,Y,binary_outcome):\n",
    "        \"\"\"\n",
    "        The 'fit' method returns a fitted model of the regressors X on the outcome Y. If binary_outcome is True, then\n",
    "        the fitted model corresponds to self.method_class_binary, with self.method_options_binary. If binary_outcome is False, then\n",
    "        the fitted model corresponds to self.method_class, with self.method_options.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X is a mxn numpy array where m is the number of observations and n is the number of regressors.\n",
    "        Y is a row vector of length m.\n",
    "        \"\"\"\n",
    "        if binary_outcome:\n",
    "            if self.method_binary==\"Tree\":\n",
    "                return self.method_class_binary.fit(X=X,y=Y).best_estimator_\n",
    "            else:\n",
    "                return self.method_class_binary.fit(X=X,y=Y)\n",
    "        else:\n",
    "            if self.method_binary==\"Tree\":\n",
    "                return self.method_class.fit(X=X,y=Y).best_estimator_\n",
    "            else:\n",
    "                return self.method_class.fit(X=X,y=Y)\n",
    "    def _find_residuals(self, y_use,y_out,x_use,x_out,binary_outcome=False):\n",
    "        \"\"\"\n",
    "        The 'find_residuals' method uses the appropriate ml method (based on binary_outcomes value), and fits\n",
    "        the ml method using the regressors x_use nad the outcome y_use. It then uses this same model to predict\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_out given x_out, and returns the predicted values of y_out and the residuals of the predicted values\n",
    "        x_use is an mxn numpy array where m is the number of observations and n is the number of regressors.\n",
    "        y_use is a row vector of length m. The same idea applies to x_out and y_out.\n",
    "        \"\"\"\n",
    "        model=self.fit(x_use,y_use,binary_outcome=binary_outcome)\n",
    "        yhat_out=model.predict(x_out)\n",
    "        res_out=y_out-yhat_out\n",
    "        return yhat_out, res_out\n",
    "    def pl_estimate(self,X,y,d,test_size=.5, normalize=True,second_order_terms=False, verbose=True, standard_errors=\"Mackinnon\"):\n",
    "        \"\"\"\n",
    "        The pl_estimate method is an implementation of the partial linear estimation procedure developed \n",
    "        in `Double Machine  Learning for Treatment and Causal Parameters' by Victor Chernozhukov,\n",
    "        Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, and Whitney Newey. It is used to estimate\n",
    "        the effect of the binary variable d on the outcome variable y, when X may be correlated with both d and y.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: mxn numpy array where m is the number of observations and n is the number of regressors.\n",
    "        y: numpy row vector of length m where y[i] corresponds to x[:,i]\n",
    "        d: numpyrow vector of length m where d[i] corresponds to x[:,i]\n",
    "        test_size : float, int (default=.5)\n",
    "            If float, should be between 0.0 and 1.0 and represent the\n",
    "            proportion of the dataset to include in the test split. If\n",
    "            int, represents the absolute number of test samples. If None,\n",
    "            the value is automatically set to the complement of the train size.\n",
    "            If train size is also None, test size is set to 0.25.\n",
    "        normalize: boolean, optional (default=True).\n",
    "            If set to true, each regressor is normalized to have a standard deviation of 1 across the sample.\n",
    "            This is strongly recommended for both lasso and ridge methods\n",
    "        second_order_terms: boolean, optional (default=False)\n",
    "            If set to true, then the machine learning method uses both all of the regressors included in X,\n",
    "            and their second order terms (each regressor squared and interactive effects).\n",
    "        verbose: boolean, optional (default=True).\n",
    "            If set to true, then the beta and standard error results will be printed \n",
    "        standard_errors: string, optional (default=\"White\")\n",
    "            Options:\n",
    "                -\"Normal\": results in normal standard errors\n",
    "                -\"White\": results in heteroskedasticity robust standard errors\n",
    "                    as in White 1980\n",
    "                -\"Mackinnon\": results in alternative heteroskedasticity robust standard errors\n",
    "                    as in Mackinnnon and White 1985\n",
    "        \"\"\"\n",
    "        start=time.time()\n",
    "        if np.sum(abs(d**2-d))>0:\n",
    "            raise NameError(\"The row vector 'd' can only have values of 0 or 1\")\n",
    "        if min(len(X),len(y),len(d))<max(len(X),len(y),len(d)):\n",
    "            raise NameError(\"X, y,and d all must have the same length\")\n",
    "        if second_order_terms:\n",
    "            X=self._so_terms(X)\n",
    "        if normalize:\n",
    "            X=self._normalize_matrix(X)\n",
    "        y_col=np.array([y]).T\n",
    "        d_col=np.array([d]).T\n",
    "        data=np.concatenate((y_col,d_col,X),axis=1)\n",
    "        split=sklearn.model_selection.train_test_split(data,test_size=test_size)\n",
    "        data_use=split[0]\n",
    "        y_use=data_use[:,0]\n",
    "        d_use=data_use[:,1]\n",
    "        x_use=data_use[:,2:]\n",
    "        data_out=split[1]\n",
    "        y_out=data_out[:,0]\n",
    "        d_out=data_out[:,1]\n",
    "        x_out=data_out[:,2:]\n",
    "        exp_d_x,res_d_x=self._find_residuals(d_use,d_out,x_use,x_out,binary_outcome=True)\n",
    "        exp_y_x,res_y_x=self._find_residuals(y_use,y_out,x_use,x_out,binary_outcome=False)\n",
    "        ols_model=sm.regression.linear_model.OLS(res_y_x,res_d_x)\n",
    "        reg=ols_model.fit()\n",
    "        res=sm.regression.linear_model.RegressionResults(ols_model, reg.params, normalized_cov_params=None, scale=1.0, cov_type='nonrobust', cov_kwds=None, use_t=None)\n",
    "        self.pl_beta=reg.params[0]\n",
    "        if standard_errors==\"Mackinnon\":\n",
    "            self.pl_se=res.HC1_se[0]\n",
    "        elif standard_errors==\"Normal\":\n",
    "            self.pl_se=res.bse[0]\n",
    "        elif standard_errors==\"White\":\n",
    "            self.pl_se=res.HC0_se[0]\n",
    "        else:\n",
    "            raise NameError(\"You have entered an unrecognized standard errors parameter value.\\nRecognized values include: 'Mackinnon', Normal', and 'White' \")\t\n",
    "        if verbose:\n",
    "            print(\"Partial Linear Estimate Results\")\n",
    "            print(\"----------------------------\")\n",
    "            print(\"Continous outcome machine learning method:\", self.method)\n",
    "            print (\"Binary outcome machine learning method:\", self.method_binary)\n",
    "            print(\"Beta=\", self.pl_beta)\n",
    "            print(\"SE=\", self.pl_se)\n",
    "            print(\"Completed in\", time.time()-start, \"seconds\")\n",
    "        return self\n",
    "    def interactive_estimate(self,X,y,d,test_size=.5,normalize=True, second_order_terms=False, drop_zero_divide=False, modify_zero_divide=1E-3,verbose=True):\n",
    "        \"\"\"\n",
    "        The interactive_estimate method is an implementation of the interactive estimation procedure developed \n",
    "        in `Double Machine  Learning for Treatment and Causal Parameters' by Victor Chernozhukov,\n",
    "        Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, and Whitney Newey. It is used to estimate\n",
    "        the effect of the binary variable d on the outcome variable y, when X may be correlated with both d and y.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: mxn numpy array where m is the number of observations and n is the number of regressors.\n",
    "        y: numpy row vector of length m where y[i] corresponds to x[:,i]\n",
    "        d: numpyrow vector of length m where d[i] corresponds to x[:,i]\n",
    "        test_size : float, int (default=.5)\n",
    "            If float, should be between 0.0 and 1.0 and represent the\n",
    "            proportion of the dataset to include in the test split. If\n",
    "            int, represents the absolute number of test samples. If None,\n",
    "            the value is automatically set to the complement of the train size.\n",
    "            If train size is also None, test size is set to 0.25.\n",
    "        normalize: boolean, optional (default=True).\n",
    "            If set to true, each regressor is normalized to have a standard deviation of 1 across the sample.\n",
    "            This is strongly recommended for both lasso and ridge methods\n",
    "        second_order_terms: boolean, optional (default=False)\n",
    "            If set to true, then the machine learning method uses both all of the regressors included in X,\n",
    "            and their second order terms (each regressor squared and interactive effects).\n",
    "        drop_zero_divide: boolean, optional (default=False). \n",
    "            If the actual value of d_out[i] is 1 but the predicted value of dhat[i] is 0 (or visa versa),\n",
    "            then the interactive estimate will necessarily have a divide by zero error.If drop_zero_divide\n",
    "            is True, then all cases in which a divide by zero error would occur will be thrown out of the sample\n",
    "        verbose: boolean, optional (default=True).\n",
    "            If set to true, then the beta and standard error results will be printed \n",
    "        modify_zero_divide: float, optional (default=1E-3). modify_zero_divide is only used if drop_zero_divide\n",
    "            is False. Whenever there is d_out[i]=1 and dhat[i]=0, dhat[i] is set to the value of modify_zero_divide.\n",
    "            Similarly, whenever d_out[i]=0 and dhat[i]=1, then dhat[i] is set to the value of modify_zero_divide.\n",
    "        \"\"\"\n",
    "        start=time.time()\n",
    "        if np.sum(abs(d**2-d))>0:\n",
    "            raise NameError(\"The row vector 'd' can only have values of 0 or 1\")\n",
    "        if min(len(X),len(y),len(d))<max(len(X),len(y),len(d)):\n",
    "            raise NameError(\"X, y,and d all must have the same length\")\n",
    "        if second_order_terms:\n",
    "            X=self._so_terms(X)\n",
    "        if normalize:\n",
    "            X=self._normalize_matrix(X)\n",
    "        y_col=np.array([y]).T\n",
    "        d_col=np.array([d]).T\n",
    "        data=np.concatenate((y_col,d_col,X),axis=1)\n",
    "        split=sklearn.model_selection.train_test_split(data,test_size=test_size)\n",
    "        data_use=split[0]\n",
    "        y_use=data_use[:,0]\n",
    "        d_use=data_use[:,1]\n",
    "        x_use=data_use[:,2:]\n",
    "        index_use1=((d_use==1).T)\n",
    "        index_use0=(0==index_use1)\n",
    "        data_use1=data_use[index_use1]\n",
    "        y_use1=y_use[index_use1]\n",
    "        x_use1=x_use[index_use1]\n",
    "        y_use0=y_use[index_use0]\n",
    "        x_use0=x_use[index_use0]\n",
    "        data_out=split[1]\n",
    "        y_out=data_out[:,0]\n",
    "        d_out=data_out[:,1]\n",
    "        x_out=data_out[:,2:]\n",
    "        yhat_d1,resy_d1=self._find_residuals(y_use1,y_out,x_use1,x_out,binary_outcome=False)\n",
    "        yhat_d0,resy_d0=self._find_residuals(y_use0,y_out,x_use0,x_out,binary_outcome=False)\n",
    "        dhat,resd=self._find_residuals(d_use,d_out,x_use,x_out,binary_outcome=True)\n",
    "        phi=yhat_d1-yhat_d0+d_out*resy_d1/dhat-((1-d_out)*resy_d0/(1-dhat))\n",
    "        dhat_zero=np.nonzero(1*(dhat==0))[0]\n",
    "        dhat_one=np.nonzero(1*(dhat==1))[0]\n",
    "        if drop_zero_divide:\n",
    "            bad_val_list=[]\n",
    "            for i in dhat_zero:\n",
    "                if d_out[i]==1:\n",
    "                    bad_val_list.append(i)\t\n",
    "                phi[i]=yhat_d1[i]-yhat_d0[i]-((1-d_out[i])*resy_d0[i]/(1-dhat[i]))\n",
    "            for i in dhat_one:\n",
    "                if d_out[i]==0:\n",
    "                    bad_val_list.append(i)\n",
    "                phi[i]=yhat_d1[i]-yhat_d0[i]+d_out[i]*resy_d1[i]/dhat[i]\n",
    "            phi=np.delete(phi,bad_val_list)\n",
    "            self.interactive_beta=np.mean(phi)\n",
    "            self.interactive_se=np.std(phi)/math.sqrt(len(phi))\n",
    "            if verbose:\n",
    "                print(\"Interactive Estimate Results\")\n",
    "                print(\"----------------------------\")\n",
    "                print(\"Continous outcome machine learning method:\", self.method)\n",
    "                print (\"Binary outcome machine learning method:\", self.method_binary)\n",
    "                print(\"Beta=\", self.interactive_beta)\n",
    "                print(\"SE=\", self.interactive_se)\n",
    "                print(\"Completed in\", time.time()-start, \"seconds\")\n",
    "            return self\n",
    "        else:\n",
    "            for i in dhat_zero:\n",
    "                if d_out[i]==1:\n",
    "                    d_out[i]=1-modify_zero_divide\n",
    "                phi[i]=yhat_d1[i]-yhat_d0[i]-((1-d_out[i])*resy_d0[i]/(1-dhat[i]))\n",
    "            for i in dhat_one:\n",
    "                if d_out[i]==0:\n",
    "                    d_out[i]=modify_zero_divide\n",
    "                phi[i]=yhat_d1[i]-yhat_d0[i]+d_out[i]*resy_d1[i]/dhat[i]\n",
    "            self.interactive_beta=np.mean(phi)\n",
    "            self.interactive_se=np.std(phi)/math.sqrt(len(phi))\n",
    "            if verbose:\n",
    "                print(\"Interactive Estimate Results\")\n",
    "                print(\"----------------------------\")\n",
    "                print(\"Continous outcome machine learning method:\", self.method)\n",
    "                print (\"Binary outcome machine learning method:\", self.method_binary)\n",
    "                print(\"Beta=\", self.interactive_beta)\n",
    "                print(\"SE=\", self.interactive_se)\n",
    "                print(\"Completed in\", time.time()-start, \"seconds\")\n",
    "            return self\n",
    "    def _so_terms(self,X):\n",
    "        \"\"\"\n",
    "        The function 'so_terms' creates a matrix featuring the first and second order terms for\n",
    "        the input matrix X, where each row in X is an observation\n",
    "        \"\"\"\n",
    "        X_copy=np.copy(X)\n",
    "        dim1=len(X_copy[0])\n",
    "        total_count=int((dim1**2)/2+dim1/2)\n",
    "        x_squared=np.zeros((len(X),total_count))\n",
    "        zero_list=[]\n",
    "        for i in range(dim1):\n",
    "            for j in range(i,dim1):\n",
    "                dim2=dim1-i\n",
    "                index=total_count-int((dim2**2)/2+dim2/2)+j-i\n",
    "                x_squared[:,index]=X_copy[:,i]*X_copy[:,j]\n",
    "                if i==j:\n",
    "                    if np.sum(X_copy[:,i]-X_copy[:,i]**2)==0:\n",
    "                        zero_list.append(index)\n",
    "        x_squared_mod=np.delete(x_squared,zero_list,1)\n",
    "        return np.concatenate((X_copy,x_squared_mod),axis=1)\n",
    "    def _normalize_matrix(self,X):\n",
    "        \"\"\"\n",
    "        The function 'normalize_matrix()' normalizes the input Matrix X by dividing each column in X\n",
    "        by its standard deviation. X is an mxn numpy array where rows correspond to observations and \n",
    "        columns correspond to regressors\n",
    "        \"\"\"\n",
    "        X_copy=np.copy(X)\n",
    "        for i in range(len(X_copy[0])):\n",
    "            X_copy[:,i:i+1]=X_copy[:,i:i+1]/np.std(X_copy[:,i:i+1])\n",
    "        return X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial Linear Estimate Results\n",
      "----------------------------\n",
      "Continous outcome machine learning method: Random Forest\n",
      "Binary outcome machine learning method: Random Forest\n",
      "Beta= 9368.358535158572\n",
      "SE= 1661.7301370742075\n",
      "Completed in 83.93489098548889 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ML2Estimator at 0x11bd65828>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML2Estimator(method=\"Random Forest\").pl_estimate(x_var,y_var,d_var,second_order_terms=True,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive Estimate Results\n",
      "----------------------------\n",
      "Continous outcome machine learning method: Random Forest\n",
      "Binary outcome machine learning method: Random Forest\n",
      "Beta= 4464.155620200678\n",
      "SE= 2649.8602557056047\n",
      "Completed in 84.7635440826416 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ML2Estimator at 0x11be30978>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML2Estimator(method=\"Random Forest\").interactive_estimate(x_var,y_var,d_var,second_order_terms=True,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial Linear Estimate Results\n",
      "----------------------------\n",
      "Continous outcome machine learning method: Random Forest\n",
      "Binary outcome machine learning method: Random Forest\n",
      "Beta= 7673.116880833988\n",
      "SE= 1617.6268368016645\n",
      "Completed in 14.913313150405884 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ML2Estimator at 0x11d0c4780>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML2Estimator(method=\"Random Forest\").pl_estimate(x_var,y_var,d_var,second_order_terms=False,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive Estimate Results\n",
      "----------------------------\n",
      "Continous outcome machine learning method: Random Forest\n",
      "Binary outcome machine learning method: Random Forest\n",
      "Beta= 6757.202929663539\n",
      "SE= 2203.8657526533575\n",
      "Completed in 14.856983184814453 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ML2Estimator at 0x130c26780>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML2Estimator(method=\"Random Forest\").interactive_estimate(x_var,y_var,d_var,second_order_terms=False,verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
